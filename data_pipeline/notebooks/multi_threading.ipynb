{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "508ccbd4-7cc6-41ac-99de-e3e56bc851b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import signal\n",
    "import logging\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from supabase import create_client, Client\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26b7c53-fb40-40ad-90f1-2ada96c83f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# CONFIGURATION\n",
    "# =====================\n",
    "VPN_CONNECT_COMMAND = r'cd \"C:\\Program Files\\NordVPN\" && nordvpn -c -g \"Netherlands\"'\n",
    "VPN_TIMEOUT = 30\n",
    "REQUEST_TIMEOUT = 10\n",
    "RETRY_LIMIT = 3\n",
    "PAGE_LIMIT_AUTOSCOUT = 20\n",
    "BATCH_SIZE = 500\n",
    "REFRESH_RATE_DB = 20\n",
    "MAX_RUNTIME_SECONDS = 12 * 3600  # 12 hours safety limit\n",
    "MAX_WORKERS = 50  # concurrent threads for fetching\n",
    "MAX_REQUESTS_PER_MIN = 100  # rate limiter\n",
    "BASE_URL = \"https://www.autoscout24.nl/lst\"\n",
    "POSTCODE_PATTERN = r'^\\d{4}[A-Z]{2}$'\n",
    "\n",
    "\n",
    "# =====================\n",
    "# GLOBALS\n",
    "# =====================\n",
    "stop_requested = False\n",
    "last_request_times = []\n",
    "rate_lock = Lock()\n",
    "\n",
    "\n",
    "# =====================\n",
    "# GRACEFUL SHUTDOWN\n",
    "# =====================\n",
    "def handle_sigint(sig, frame):\n",
    "    global stop_requested\n",
    "    logging.warning(\"Shutdown signal received. Finishing current batch and exiting...\")\n",
    "    stop_requested = True\n",
    "\n",
    "\n",
    "signal.signal(signal.SIGINT, handle_sigint)\n",
    "\n",
    "\n",
    "# =====================\n",
    "# HELPERS\n",
    "# =====================\n",
    "def is_valid_format(s, pattern):\n",
    "    return bool(re.fullmatch(pattern, s))\n",
    "\n",
    "\n",
    "def rate_limit():\n",
    "    \"\"\"Ensure we do not exceed MAX_REQUESTS_PER_MIN.\"\"\"\n",
    "    global last_request_times\n",
    "    with rate_lock:\n",
    "        now = time.time()\n",
    "        # Keep only last 60 seconds of requests\n",
    "        last_request_times = [t for t in last_request_times if now - t < 60]\n",
    "\n",
    "        if len(last_request_times) >= MAX_REQUESTS_PER_MIN:\n",
    "            sleep_time = 60 - (now - last_request_times[0])\n",
    "            logging.info(f\"Rate limit reached. Sleeping for {sleep_time:.2f} seconds...\")\n",
    "            time.sleep(sleep_time)\n",
    "            last_request_times = [t for t in last_request_times if now - t < 60]\n",
    "\n",
    "        last_request_times.append(time.time())\n",
    "\n",
    "\n",
    "def safe_request(url, params=None):\n",
    "    \"\"\"Perform HTTP request with retry, timeout, rate limiting, and proxy rotation.\"\"\"\n",
    "    for attempt in range(RETRY_LIMIT):\n",
    "        if stop_requested:\n",
    "            return None\n",
    "        try:\n",
    "            rate_limit()\n",
    "            response = requests.get(url, params=params, timeout=REQUEST_TIMEOUT)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except (requests.exceptions.RequestException, requests.exceptions.Timeout) as e:\n",
    "            logging.warning(f\"Request attempt {attempt + 1} failed: {e}\")\n",
    "            time.sleep(1)\n",
    "    logging.error(f\"Failed to fetch data after {RETRY_LIMIT} attempts. Skipping...\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_command_with_timeout(command, timeout):\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=timeout)\n",
    "        return result\n",
    "    except subprocess.TimeoutExpired:\n",
    "        logging.error(f\"Command timed out after {timeout} seconds.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# =====================\n",
    "# DATA EXTRACTION\n",
    "# =====================\n",
    "def extract_car_data(car, postcode_pattern):\n",
    "    try:\n",
    "        car_id = car.get(\"id\")\n",
    "        if not car_id:\n",
    "            return None\n",
    "\n",
    "        data_mileage = float(car.get(\"data-mileage\") or -1)\n",
    "        listing_price = float(car.get(\"data-price\") or -1)\n",
    "        raw_postcode = car.get(\"data-listing-zip-code\")\n",
    "        postcode = raw_postcode[0:4] + raw_postcode[-2:].upper() if raw_postcode else None\n",
    "        if postcode and not is_valid_format(postcode, postcode_pattern):\n",
    "            postcode = None\n",
    "\n",
    "        transmission_text = car.find(\"span\", {\"data-testid\": \"VehicleDetails-transmission\"})\n",
    "        fuel_text = car.find(\"span\", {\"data-testid\": \"VehicleDetails-gas_pump\"})\n",
    "        power_text = car.find(\"span\", {\"data-testid\": \"VehicleDetails-speedometer\"})\n",
    "        power_text = power_text.get_text(strip=True) if power_text else None\n",
    "\n",
    "        kw_value, pk_value = None, None\n",
    "        if power_text:\n",
    "            match = re.search(r\"(\\d+)\\s*kW.*\\((\\d+)\\s*PK\\)\", power_text)\n",
    "            if match:\n",
    "                kw_value = float(match.group(1))\n",
    "                pk_value = float(match.group(2))\n",
    "\n",
    "        return {\n",
    "            \"car_id\": car_id,\n",
    "            \"make\": car.get(\"data-make\"),\n",
    "            \"model\": car.get(\"data-model\"),\n",
    "            \"first_registration\": car.get(\"data-first-registration\"),\n",
    "            \"fuel_type\": car.get(\"data-fuel-type\"),\n",
    "            \"mileage\": data_mileage,\n",
    "            \"post_code_raw\": raw_postcode,\n",
    "            \"post_code\": postcode,\n",
    "            \"listing_price\": listing_price,\n",
    "            \"transmission\": transmission_text.get_text(strip=True) if transmission_text else None,\n",
    "            \"fuel_text\": fuel_text.get_text(strip=True) if fuel_text else None,\n",
    "            \"power_text\": power_text,\n",
    "            \"power_kw\": kw_value,\n",
    "            \"power_pk\": pk_value\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting car data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_page(params):\n",
    "    \"\"\"Fetch and parse one page from AutoScout.\"\"\"\n",
    "    if stop_requested:\n",
    "        return []\n",
    "\n",
    "    html = safe_request(BASE_URL, params=params)\n",
    "    if not html:\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    car_listings = soup.find_all(\"article\", class_=\"cldt-summary-full-item\")\n",
    "\n",
    "    results = []\n",
    "    for car in car_listings:\n",
    "        car_info = extract_car_data(car, POSTCODE_PATTERN)\n",
    "        if car_info:\n",
    "            results.append(car_info)\n",
    "    return results\n",
    "\n",
    "\n",
    "# =====================\n",
    "# MAIN SCRIPT\n",
    "# =====================\n",
    "def main():\n",
    "    global stop_requested\n",
    "    # Initialize logging\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    logging.basicConfig(filename=f\"../logging/script_log_{timestamp}.log\", level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logging.info('Script started with concurrency, rate limiting, and proxy rotation.')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Enable VPN\n",
    "    # logging.info(\"Connecting to VPN...\")\n",
    "    # vpn_result = run_command_with_timeout(VPN_CONNECT_COMMAND, VPN_TIMEOUT)\n",
    "    # if vpn_result and vpn_result.returncode == 0:\n",
    "    #     logging.info(\"VPN connection established successfully.\")\n",
    "    # else:\n",
    "    #     logging.error(\"Failed to establish VPN connection.\")\n",
    "    #     sys.exit(1)\n",
    "\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "    supabase_url = os.getenv(\"SUPABASE_URL\")\n",
    "    supabase_key = os.getenv(\"SUPABASE_KEY\")\n",
    "    if not supabase_url or not supabase_key:\n",
    "        logging.error(\"Supabase credentials missing in .env file.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    supabase: Client = create_client(supabase_url, supabase_key)\n",
    "    table_name = \"autoscout_car_adverts\"\n",
    "\n",
    "    # Fetch initial car IDs\n",
    "    try:\n",
    "        response = supabase.table(table_name).select(\"car_id\").execute()\n",
    "        car_ids_in_database = {d['car_id'] for d in response.data}\n",
    "        logging.info(f\"Found {len(car_ids_in_database)} existing car IDs.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to fetch initial data from Supabase: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Define price and mileage ranges\n",
    "    price_vec = np.array([0, 500, 1000])\n",
    "    km_vec = np.array([0, 1000, 5000])\n",
    "\n",
    "    cars_to_insert = []\n",
    "    car_ids_in_upsert = set()\n",
    "    batch_lock = Lock()\n",
    "    count_added = 0\n",
    "\n",
    "    # =====================\n",
    "    # MAIN LOOPS WITH CONCURRENCY\n",
    "    # =====================\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_params = {}\n",
    "\n",
    "        for k, price in enumerate(price_vec[:-1]):\n",
    "            if stop_requested or time.time() - start_time > MAX_RUNTIME_SECONDS:\n",
    "                break\n",
    "\n",
    "            for j, km in enumerate(km_vec[:-1]):\n",
    "                if stop_requested or time.time() - start_time > MAX_RUNTIME_SECONDS:\n",
    "                    break\n",
    "\n",
    "                for i in range(PAGE_LIMIT_AUTOSCOUT):\n",
    "                    params = {\n",
    "                        \"atype\": \"C\",\n",
    "                        \"cy\": \"NL\",\n",
    "                        \"damaged_listing\": \"exclude\",\n",
    "                        \"desc\": \"1\",\n",
    "                        \"powertype\": \"kw\",\n",
    "                        \"sort\": \"age\",\n",
    "                        \"source\": \"homepage_search-mask\",\n",
    "                        \"ustate\": \"N,U\",\n",
    "                        \"pricefrom\": int(price_vec[k]),\n",
    "                        \"priceto\": int(price_vec[k + 1]),\n",
    "                        \"kmfrom\": int(km_vec[j]),\n",
    "                        \"kmto\": int(km_vec[j + 1]),\n",
    "                        \"page\": i + 1\n",
    "                    }\n",
    "                    future = executor.submit(fetch_page, params)\n",
    "                    future_to_params[future] = params\n",
    "\n",
    "        for future in tqdm(as_completed(future_to_params), total=len(future_to_params), desc=\"Processing Tasks\" ):\n",
    "            if stop_requested:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                page_results = future.result()\n",
    "                if not page_results:\n",
    "                    continue\n",
    "\n",
    "                with batch_lock:\n",
    "                    for car in page_results:\n",
    "                        car_id = car[\"car_id\"]\n",
    "                        if car_id not in car_ids_in_upsert:\n",
    "                            cars_to_insert.append(car)\n",
    "                            car_ids_in_database.add(car_id)\n",
    "                            car_ids_in_upsert.add(car_id)\n",
    "\n",
    "                    if len(cars_to_insert) >= BATCH_SIZE:\n",
    "                        supabase.table(table_name).upsert(cars_to_insert, ignore_duplicates=True).execute()\n",
    "                        count_added += len(cars_to_insert)\n",
    "                        logging.info(f\"Inserted {count_added} cars so far...\")\n",
    "                        cars_to_insert = []\n",
    "                        car_ids_in_upsert = set()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing future: {e}\")\n",
    "\n",
    "    # Flush remaining cars\n",
    "    if cars_to_insert:\n",
    "        supabase.table(table_name).upsert(cars_to_insert).execute()\n",
    "        count_added += len(cars_to_insert)\n",
    "\n",
    "    logging.info(f\"Script finished. Total cars added: {count_added}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384e8f72-5854-4ab7-a000-40d51c218e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Tasks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:02<00:00, 36.56it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672def00-73d1-41f5-bf3b-f8382c0be6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b9846-758b-4231-bf72-db0984abacb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c94fc4-07d8-456f-b0a2-d596ceeca380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e1b494-653f-4fdb-bad7-021a6dbdb03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8604c-b42d-4ad8-9309-b72f5aa4b799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde1789-7b26-4ff8-99b0-08842ede0b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5515f689-9370-4a2e-a201-e24ad42cc69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def task(n):\n",
    "    time.sleep(n)\n",
    "    return n\n",
    "\n",
    "tasks = [1, 2, 3, 4, 5]\n",
    "completed_count = 0\n",
    "future_to_params = {}\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    for t in tasks:\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                future = executor.submit(task, t) \n",
    "                future_to_params[future] = t\n",
    "\n",
    "    for future in tqdm(as_completed(future_to_params), total=len(future_to_params)):\n",
    "        result = future.result()\n",
    "        completed_count += 1\n",
    "        # print(f\"Task finished with result {result}, completed {completed_count}/{len(tasks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f462ca1-9d86-4f0a-83bd-638cf876bb50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
